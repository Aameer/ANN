{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "# taken from lukas/ml-class\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Digit [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.imshow(X_train[0])\n",
    "plt.imshow(X_train[1], cmap=\"gray\")\n",
    "plt.title(\"Digit {}\".format(y_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.image_height = img_height\n",
    "config.image_width = img_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = y_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(img_width, img_height)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Trains the model for a given number of epochs (iterations on a dataset).\n",
       "\n",
       "# Arguments\n",
       "    x: Numpy array of training data (if the model has a single input),\n",
       "        or list of Numpy arrays (if the model has multiple inputs).\n",
       "        If input layers in the model are named, you can also pass a\n",
       "        dictionary mapping input names to Numpy arrays.\n",
       "        `x` can be `None` (default) if feeding from\n",
       "        framework-native tensors (e.g. TensorFlow data tensors).\n",
       "    y: Numpy array of target (label) data\n",
       "        (if the model has a single output),\n",
       "        or list of Numpy arrays (if the model has multiple outputs).\n",
       "        If output layers in the model are named, you can also pass a\n",
       "        dictionary mapping output names to Numpy arrays.\n",
       "        `y` can be `None` (default) if feeding from\n",
       "        framework-native tensors (e.g. TensorFlow data tensors).\n",
       "    batch_size: Integer or `None`.\n",
       "        Number of samples per gradient update.\n",
       "        If unspecified, `batch_size` will default to 32.\n",
       "    epochs: Integer. Number of epochs to train the model.\n",
       "        An epoch is an iteration over the entire `x` and `y`\n",
       "        data provided.\n",
       "        Note that in conjunction with `initial_epoch`,\n",
       "        `epochs` is to be understood as \"final epoch\".\n",
       "        The model is not trained for a number of iterations\n",
       "        given by `epochs`, but merely until the epoch\n",
       "        of index `epochs` is reached.\n",
       "    verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
       "        0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
       "    callbacks: List of `keras.callbacks.Callback` instances.\n",
       "        List of callbacks to apply during training.\n",
       "        See [callbacks](/callbacks).\n",
       "    validation_split: Float between 0 and 1.\n",
       "        Fraction of the training data to be used as validation data.\n",
       "        The model will set apart this fraction of the training data,\n",
       "        will not train on it, and will evaluate\n",
       "        the loss and any model metrics\n",
       "        on this data at the end of each epoch.\n",
       "        The validation data is selected from the last samples\n",
       "        in the `x` and `y` data provided, before shuffling.\n",
       "    validation_data: tuple `(x_val, y_val)` or tuple\n",
       "        `(x_val, y_val, val_sample_weights)` on which to evaluate\n",
       "        the loss and any model metrics at the end of each epoch.\n",
       "        The model will not be trained on this data.\n",
       "        `validation_data` will override `validation_split`.\n",
       "    shuffle: Boolean (whether to shuffle the training data\n",
       "        before each epoch) or str (for 'batch').\n",
       "        'batch' is a special option for dealing with the\n",
       "        limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
       "        Has no effect when `steps_per_epoch` is not `None`.\n",
       "    class_weight: Optional dictionary mapping class indices (integers)\n",
       "        to a weight (float) value, used for weighting the loss function\n",
       "        (during training only).\n",
       "        This can be useful to tell the model to\n",
       "        \"pay more attention\" to samples from\n",
       "        an under-represented class.\n",
       "    sample_weight: Optional Numpy array of weights for\n",
       "        the training samples, used for weighting the loss function\n",
       "        (during training only). You can either pass a flat (1D)\n",
       "        Numpy array with the same length as the input samples\n",
       "        (1:1 mapping between weights and samples),\n",
       "        or in the case of temporal data,\n",
       "        you can pass a 2D array with shape\n",
       "        `(samples, sequence_length)`,\n",
       "        to apply a different weight to every timestep of every sample.\n",
       "        In this case you should make sure to specify\n",
       "        `sample_weight_mode=\"temporal\"` in `compile()`.\n",
       "    initial_epoch: Integer.\n",
       "        Epoch at which to start training\n",
       "        (useful for resuming a previous training run).\n",
       "    steps_per_epoch: Integer or `None`.\n",
       "        Total number of steps (batches of samples)\n",
       "        before declaring one epoch finished and starting the\n",
       "        next epoch. When training with input tensors such as\n",
       "        TensorFlow data tensors, the default `None` is equal to\n",
       "        the number of samples in your dataset divided by\n",
       "        the batch size, or 1 if that cannot be determined.\n",
       "    validation_steps: Only relevant if `steps_per_epoch`\n",
       "        is specified. Total number of steps (batches of samples)\n",
       "        to validate before stopping.\n",
       "\n",
       "# Returns\n",
       "    A `History` object. Its `History.history` attribute is\n",
       "    a record of training loss values and metrics values\n",
       "    at successive epochs, as well as validation loss values\n",
       "    and validation metrics values (if applicable).\n",
       "\n",
       "# Raises\n",
       "    RuntimeError: If the model was never compiled.\n",
       "    ValueError: In case of mismatch between the provided input data\n",
       "        and what the model expects.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/keras/engine/training.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/univai-ss2019/mnist-logistic-ann/runs/rm22egft\n",
      "Call `%%wandb` in the cell containing your training loop to display live results.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 4.6819 - acc: 0.7079 - val_loss: 4.5897 - val_acc: 0.7139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.1 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 4.5749 - acc: 0.7150 - val_loss: 4.5972 - val_acc: 0.7136\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.5479 - acc: 0.7166 - val_loss: 4.5732 - val_acc: 0.7149\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.5459 - acc: 0.7163 - val_loss: 4.5958 - val_acc: 0.7136\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.5539 - acc: 0.7160 - val_loss: 4.5646 - val_acc: 0.7152\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 4.5256 - acc: 0.7178 - val_loss: 4.5274 - val_acc: 0.7174\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.4967 - acc: 0.7199 - val_loss: 4.5264 - val_acc: 0.7176\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 4.5166 - acc: 0.7182 - val_loss: 4.4979 - val_acc: 0.7192\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.4868 - acc: 0.7203 - val_loss: 4.5343 - val_acc: 0.7170\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.5052 - acc: 0.7191 - val_loss: 4.5541 - val_acc: 0.7164\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.4714 - acc: 0.7211 - val_loss: 4.4700 - val_acc: 0.7207\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 4.4656 - acc: 0.7216 - val_loss: 4.4820 - val_acc: 0.7206\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.4991 - acc: 0.7195 - val_loss: 4.5665 - val_acc: 0.7148\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.4646 - acc: 0.7217 - val_loss: 4.4864 - val_acc: 0.7207\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.4705 - acc: 0.7214 - val_loss: 4.5038 - val_acc: 0.7192\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 4.4627 - acc: 0.7219 - val_loss: 4.4942 - val_acc: 0.7199\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.4568 - acc: 0.7222 - val_loss: 4.5708 - val_acc: 0.7151\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.4677 - acc: 0.7214 - val_loss: 4.6552 - val_acc: 0.7095\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.4787 - acc: 0.7209 - val_loss: 4.5045 - val_acc: 0.7192\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.4774 - acc: 0.7209 - val_loss: 4.5957 - val_acc: 0.7136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08c86cae48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# logging code\n",
    "run = wandb.init()\n",
    "config = run.config\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=200,validation_data=(X_test, y_test),\n",
    "          callbacks=[WandbCallback(data_type=\"image\", labels=labels, save_model=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
